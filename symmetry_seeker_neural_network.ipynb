{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablocalvo7/Symmetry_Seeker_NN/blob/main/symmetry_seeker_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "O7EggnQhnVkK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p3Z_HuCBPRy"
      },
      "source": [
        "#Your google drive is made accesible to Colab.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    %cd /content/drive/MyDrive/.../\n",
        "    %ls -lht\n",
        "    # To import own packages set local path in packages syspath\n",
        "    import sys\n",
        "    sys.path.insert(0,\"./\")\n",
        "except ImportError:\n",
        "    print(\"You are not in google.colab!!\")\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main imports"
      ],
      "metadata": {
        "id": "sD3mQaex2x8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Input,Dense\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "HCuTD9gJ2wcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Symmetric Seeker Neural Network $\\rightarrow$ SymSeekerNN class"
      ],
      "metadata": {
        "id": "jswK_WdInX-p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvQ-paBYBR_q"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.keras.engine import compile_utils\n",
        "\n",
        "class SymSeekerNN(tf.keras.Model):\n",
        "    '''\n",
        "    Description\n",
        "    '''\n",
        "    def __init__(self,Nfeatures,Nbranches,\n",
        "                 input_layer=None,\n",
        "                 standard_layers=None,\n",
        "                 branches_output=None,\n",
        "                 model_saved=None):\n",
        "        super(SymSeekerNN, self).__init__()\n",
        "\n",
        "        self.Nfeatures=Nfeatures\n",
        "        self.Nbranches=Nbranches\n",
        "        #try... except\n",
        "        if(model_saved!=None):\n",
        "          self.model=model_saved\n",
        "        else:\n",
        "          self.input_layer=input_layer\n",
        "          self.standard_layers=standard_layers\n",
        "          # Latent layer\n",
        "          self.latent_layer = standard_layers.layers[-1]\n",
        "          self.latent_layer.units=(self.Nfeatures)\n",
        "          # Branches\n",
        "          self.branches_output = branches_output\n",
        "          self.branches_output.units=int(self.Nfeatures*self.Nbranches)\n",
        "          self.branches_output.use_bias= False\n",
        "          self.branches_output.activation=None\n",
        "          self.model=Sequential([self.input_layer,\n",
        "                                self.standard_layers,\n",
        "                                self.branches_output])\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(cls, path,Nfeatures,Nbranches):\n",
        "        model_saved=models.load_model(path,compile=False)\n",
        "        # Create an instance of the custom model class using the provided config\n",
        "        model = cls(Nfeatures,Nbranches,model_saved=model_saved)\n",
        "        # Perform any additional customizations if required\n",
        "        return model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # The usual forward pass of the model\n",
        "        return self.model(inputs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(SymSeekerNN, self).get_config()\n",
        "        # Add any custom configurations to the config dictionary\n",
        "        custom_methods = {\n",
        "            'summary' : self.summary.__name__,\n",
        "            'symmetry_loss_Nb'  : self.symmetry_loss_Nb.__name__,\n",
        "            'calculate_d_closed': self.calculate_d_closed.__name__,\n",
        "            'calculate_d_inv'   : self.calculate_d_inv.__name__,\n",
        "            'obtain_list_branch_matrices_ref' : self.obtain_list_branch_matrices_ref.__name__,\n",
        "            '_list_acting_branches' : self._list_acting_branches.__name__,\n",
        "            'activity_single_branch' : self.activity_single_branch.__name__,\n",
        "            'list_activities' : self.list_activities.__name__\n",
        "        }\n",
        "        config['custom_methods'] = custom_methods\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        # Create an instance of the custom model class using the provided config\n",
        "        model = cls()\n",
        "        # Perform any additional customizations if required\n",
        "        return model\n",
        "\n",
        "    def summary(self):\n",
        "       return self.model.summary()\n",
        "\n",
        "    def evaluate_loss(self,x_true,x_pred):\n",
        "       return self.loss(x_true,x_pred)\n",
        "\n",
        "    def compile(self, optimizer='adam',**kwargs):\n",
        "        super(SymSeekerNN, self).compile(**kwargs)\n",
        "        self.optimizer= optimizer\n",
        "        # Uses symmetry_loss_Nb\n",
        "        self.loss=self.symmetry_loss_Nb(self.Nbranches,self.Nfeatures)\n",
        "        loss_weights=None\n",
        "        self.output_names = None\n",
        "        self.model.compile(loss=self.loss)\n",
        "        self.compiled_loss = compile_utils.LossesContainer(\n",
        "          self.loss, loss_weights, output_names=self.output_names)\n",
        "\n",
        "    def symmetry_loss_Nb(self,Nbranches,Nfeatures):\n",
        "      '''\n",
        "      description\n",
        "      '''\n",
        "      def NBsym_loss(x_true,x_pred):\n",
        "\n",
        "          mbs = tf.shape(x_pred)[0]\n",
        "\n",
        "          x_true = tf.cast(x_true, dtype = 'float32')\n",
        "          x_pred = tf.cast(x_pred, dtype = 'float32')\n",
        "\n",
        "          diff_squared = (x_pred-x_true)*(x_pred-x_true)\n",
        "          sum_kernel = tf.constant(np.ones((1,Nfeatures)),tf.float32)\n",
        "          cost_matrix = tf.nn.conv2d(tf.reshape(diff_squared,(1,mbs,int(Nfeatures*Nbranches),1)),tf.reshape(sum_kernel,(1,Nfeatures,1,1)),strides=[1,Nfeatures],padding='VALID')\n",
        "          cost_matrix = tf.reshape(cost_matrix,(mbs,Nbranches))\n",
        "\n",
        "          cost_matrix = 0.5*cost_matrix\n",
        "          cost_vector = tf.math.reduce_min(cost_matrix, axis=1)\n",
        "          mbs = tf.cast(mbs, dtype = 'float32')\n",
        "          loss = tf.math.reduce_sum(cost_vector)/mbs\n",
        "          return loss\n",
        "      return NBsym_loss\n",
        "\n",
        "    def obtain_list_branch_matrices_ref(self,index_reference):\n",
        "      '''\n",
        "      index_reference goes from 0 to Nbranches-1\n",
        "      '''\n",
        "      w = self.model.get_weights()\n",
        "      w_ref_inv = np.linalg.inv(w[-1][0:self.Nfeatures,index_reference*self.Nfeatures:(index_reference+1)*self.Nfeatures])\n",
        "      list_mats = []\n",
        "      for branch in range(self.Nbranches):\n",
        "          real_branch = w[-1][0:self.Nfeatures,branch*self.Nfeatures:(branch+1)*self.Nfeatures]\n",
        "          list_mats.append( np.matmul(w_ref_inv,real_branch) )\n",
        "      return list_mats\n",
        "\n",
        "    def calculate_d_closed(self,index_reference):\n",
        "      list_mats=self.obtain_list_branch_matrices_ref(index_reference)\n",
        "      sum = 0.0\n",
        "      for alpha in list_mats:\n",
        "          for beta in list_mats:\n",
        "              Wab = np.matmul(alpha,beta)\n",
        "              min = 100000000000000.0\n",
        "              for gamma in list_mats:\n",
        "                  Wab_Wg = Wab - gamma\n",
        "                  loss = np.sum( np.absolute( Wab_Wg ) )\n",
        "                  if(loss<min):\n",
        "                      min = loss\n",
        "              sum = sum + min\n",
        "      d_closed = sum/(self.Nfeatures*self.Nfeatures*self.Nbranches*self.Nbranches)\n",
        "      return d_closed\n",
        "\n",
        "    def calculate_d_inv(self,index_reference):\n",
        "      '''\n",
        "      Eq. XX in Calvo-BarlÃ©s et al. ....\n",
        "      '''\n",
        "      list_mats=self.obtain_list_branch_matrices_ref(index_reference)\n",
        "      sum2 = 0.0\n",
        "      for alpha in list_mats:\n",
        "          Wa_inv = np.linalg.inv(alpha)\n",
        "          min2 = 100000000000000.0\n",
        "          for gamma in list_mats:\n",
        "              Wa_inv_Wg = Wa_inv - gamma\n",
        "              loss2 = np.sum( np.absolute (Wa_inv_Wg ) )\n",
        "              if(loss2 < min2):\n",
        "                  min2=loss2\n",
        "          sum2 = sum2 + min2\n",
        "      d_inv = sum2/(self.Nfeatures*self.Nfeatures*self.Nbranches)\n",
        "      return d_inv\n",
        "\n",
        "    def _list_acting_branches(self,x_true,x_pred):\n",
        "        '''\n",
        "        Returns a list of size ntrain that gives the branch index with the minimum MSE\n",
        "        '''\n",
        "        ndata = np.shape(x_true)[0]\n",
        "\n",
        "        cost_matrix = (x_pred[:,0]-x_true[:,0])*(x_pred[:,0]-x_true[:,0])\n",
        "        for j in range(1,self.Nfeatures):\n",
        "            cost_matrix = cost_matrix + (x_pred[:,j]-x_true[:,j])*(x_pred[:,j]-x_true[:,j])\n",
        "\n",
        "        for i in range(1,self.Nbranches):\n",
        "            cost_column = (x_pred[:,self.Nfeatures*i]-x_true[:,0])*(x_pred[:,self.Nfeatures*i]-x_true[:,0])\n",
        "            for j in range(1,self.Nfeatures):\n",
        "                cost_column = cost_column + (x_pred[:,self.Nfeatures*i+j]-x_true[:,j])*(x_pred[:,self.Nfeatures*i+j]-x_true[:,j])\n",
        "\n",
        "            cost_matrix = np.concatenate((cost_matrix,cost_column), axis = 0)\n",
        "\n",
        "        cost_matrix = np.reshape(cost_matrix,(self.Nbranches,ndata))\n",
        "        cost_matrix = np.transpose(cost_matrix)\n",
        "        cost_matrix = 0.5*cost_matrix\n",
        "        return np.argmin(cost_matrix,axis=1)\n",
        "\n",
        "    def activity_single_branch(self,branch_to_evaluate,x_true,x_pred):\n",
        "        '''\n",
        "        Returns the activity of the branch with index \"branch_to_evaluate\"\n",
        "        '''\n",
        "        ntrain = np.shape(x_true)[0]\n",
        "        ##### CALCULATE column_mins #####\n",
        "        column_mins = self._list_acting_branches(x_true,x_pred)\n",
        "        column_mins = list(column_mins)\n",
        "        ##### CALCULATE list_counter #####\n",
        "        list_percentage = []\n",
        "        for i in range(self.Nbranches):\n",
        "            list_percentage.append((column_mins.count(i)*100)/ntrain)\n",
        "        return list_percentage[branch_to_evaluate]\n",
        "\n",
        "    def list_activities(self,x_true,x_pred):\n",
        "        '''\n",
        "        Returns the list of activities of all the branches\n",
        "        '''\n",
        "        ntrain = np.shape(x_true)[0]\n",
        "        ##### CALCULATE column_mins #####\n",
        "        column_mins = self._list_acting_branches(x_true,x_pred)\n",
        "        column_mins = list(column_mins)\n",
        "        ##### CALCULATE list_counter #####\n",
        "        list_percentage = []\n",
        "        for i in range(self.Nbranches):\n",
        "            list_percentage.append((column_mins.count(i)*100)/ntrain)\n",
        "        return list_percentage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SymSeekNN Class information"
      ],
      "metadata": {
        "id": "58jfJn7BILJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class class information\n",
        "print(SymSeekerNN.__doc__)\n",
        "\n",
        "# Methods available\n",
        "method_list = [method for method in dir(SymSeekerNN) if method.startswith('__') is False]\n",
        "print(\"Methods defined for class \",SymSeekerNN.__name__)\n",
        "\n",
        "for method in method_list:\n",
        "  print(method)\n",
        "print('\\n')\n",
        "\n",
        "# Description of the method (if available)\n",
        "# From the list below write print(SymSeekerNN.name_of_the_method.__doc__)\n",
        "# For example\n",
        "print(\"Method=\",SymSeekerNN.symmetry_loss_Nb.__name__)\n",
        "print(SymSeekerNN.symmetry_loss_Nb.__doc__)"
      ],
      "metadata": {
        "id": "ZyWugMTmDv__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate the data"
      ],
      "metadata": {
        "id": "QXDMyXNgDyH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def z_power_n(x,y,n):\n",
        "    z = x + 1j*y\n",
        "    w = z**n\n",
        "    return np.real(w),np.imag(w)\n",
        "\n",
        "Nsamples = 20000 #Number of samples for training/validation data\n",
        "L = 10.0\n",
        "n = 3\n",
        "problem_name = str(n)+'root'\n",
        "\n",
        "# GENERATE DATA\n",
        "x = [] #Physical features\n",
        "y = [] #Measurable magnitudes\n",
        "\n",
        "for i in range(Nsamples):\n",
        "    #print('Sample #',i)\n",
        "    #polar coordinates\n",
        "    rho = np.random.uniform(0,L)\n",
        "    phi = np.random.uniform(0,2*np.pi) #np.random.normal(np.pi/2, np.pi/4) (gaussian)\n",
        "    xx = rho*np.cos(phi); yy = rho*np.sin(phi)\n",
        "    single_x = [xx,yy]\n",
        "    single_y = z_power_n(xx,yy,n)\n",
        "    x.append(single_x)\n",
        "    y.append(single_y)\n",
        "x = np.array(x)  # w\n",
        "y = np.array(y)  # z^n"
      ],
      "metadata": {
        "id": "iK9PJa9wC3QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define tranining and validation dataset"
      ],
      "metadata": {
        "id": "ag2TSTLq2-qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ntrain = int(0.95*Nsamples)\n",
        "nvalidation = Nsamples-ntrain\n",
        "\n",
        "Nfeatures = y.shape[1]\n",
        "L = 10.0\n",
        "n = 3\n",
        "x = x/L\n",
        "y = y/(L**n)\n",
        "problem_name = str(n)+'root'\n",
        "\n",
        "xtr_single = x[0:ntrain,:]\n",
        "xva_single = x[ntrain:ntrain + nvalidation, :]\n",
        "ytr = y[0:ntrain,:]\n",
        "yva = y[ntrain:ntrain + nvalidation, :]\n",
        "\n",
        "print(xtr_single.shape,xva_single.shape)"
      ],
      "metadata": {
        "id": "VB5aurY02-wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the SNNN network"
      ],
      "metadata": {
        "id": "T8CIqUk3BmR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "minib_size = 128\n",
        "eta = 0.01\n",
        "Nbranches = 3 #The training process starts with a NN with \"max_Nbranches\" branches\n",
        "\n",
        "# Save the models\n",
        "directory = './models_'+str(problem_name)+'/'\n",
        "\n",
        "# 0) EXPAND TRAINING OUTPUTS\n",
        "#ytr = np.tile(ytr_single,reps=(1,Nbranches))\n",
        "#yva = np.tile(yva_single,reps=(1,Nbranches))\n",
        "#output_neurons = ytr.shape[1]\n",
        "\n",
        "xtr = np.tile(xtr_single,reps=(1,Nbranches))\n",
        "xva = np.tile(xva_single,reps=(1,Nbranches))\n",
        "output_neurons = xtr.shape[1]\n",
        "\n",
        "# 1) DEFINE THE MODEL\n",
        "# Input layer\n",
        "input_neurons  = ytr.shape[1]\n",
        "input_layer = Input(shape=(input_neurons,))\n",
        "\n",
        "# Standard model\n",
        "nneurons = 10; nhidden = 2\n",
        "standard_layers=Sequential()\n",
        "hidden_layer = Dense(nneurons, activation='sigmoid' ,\n",
        "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1/np.sqrt(input_neurons)),\n",
        "                     bias_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1))\n",
        "standard_layers.add(hidden_layer)\n",
        "for j in range(1,nhidden):\n",
        "    hidden_layer = Dense(nneurons, activation='sigmoid' ,\n",
        "                         kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1/np.sqrt(nneurons)),\n",
        "                         bias_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1))\n",
        "    standard_layers.add(hidden_layer)\n",
        "\n",
        "# Latent layer\n",
        "latent_layer = Dense(1,activation=None,\n",
        "                     kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1/np.sqrt(nneurons)),\n",
        "                     bias_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=1))\n",
        "\n",
        "standard_layers.add(latent_layer)\n",
        "\n",
        "# Branches\n",
        "branches_output = Dense(1,\n",
        "                        kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1/np.sqrt(Nfeatures)))\n",
        "\n",
        "model=SymSeekerNN(Nfeatures,Nbranches,\n",
        "                  input_layer,\n",
        "                  standard_layers,\n",
        "                  branches_output)\n",
        "\n",
        "# 3) COMPILE THE MODEL\n",
        "name_opt='Adam'\n",
        "opt = tf.keras.optimizers.Adam(eta)\n",
        "model.compile(optimizer=opt)\n",
        "model.summary()\n",
        "\n",
        "# 3) FIT THE MODEL\n",
        "r = model.fit(ytr, xtr, batch_size = minib_size, epochs=epochs,verbose=1, validation_data=(yva, xva))\n",
        "\n",
        "# 4) SAVE THE MODEL\n",
        "i=0\n",
        "file_name = 'Model_'+str(i)+'sim_'+str(Nbranches)+'branches'\n",
        "model.save(directory+'/'+file_name)\n",
        "\n",
        "# 5) PLOT THE LOSS\n",
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'],label='val loss')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "metadata": {
        "id": "SP6WME9kWCeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate metrics based on SymSeekerNN class"
      ],
      "metadata": {
        "id": "t8--9GP4CQTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model (if previously saved in a file)"
      ],
      "metadata": {
        "id": "nFsZTe2_Hcfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=3\n",
        "problem_name = str(n)+'root'\n",
        "Nfeatures=2\n",
        "Nbranches=3\n",
        "sim=0\n",
        "path='./models_'+problem_name+'/Model_'+str(sim)+'sim_'+str(Nbranches)+'branches'\n",
        "model=SymSeekerNN.load_model(path,Nfeatures,Nbranches)\n",
        "model.compile(optimizer='adam')\n"
      ],
      "metadata": {
        "id": "eOpAkE2PcAG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative way ...\n",
        "print('path=',path)\n",
        "model_saved=models.load_model(path,compile=False)\n",
        "model=SymSeekerNN(Nfeatures=Nfeatures,\n",
        "                  Nbranches=Nbranches,\n",
        "                  model_saved=model_saved)\n",
        "model.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "Ut7cCgLIk_RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction of $x$"
      ],
      "metadata": {
        "id": "-8ApMon8ygR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xtr = np.tile(xtr_single,reps=(1,Nbranches))\n",
        "\n",
        "model.summary()\n",
        "xtr_NN = model.predict(ytr)\n",
        "score=model.evaluate_loss(xtr,xtr_NN)\n",
        "print(\"Loss=\",score.numpy())\n",
        "print(xtr_NN.shape,ytr.shape)\n",
        "\n",
        "true_data=False\n",
        "if(true_data):\n",
        "  x=xtr;Nb=1\n",
        "else:\n",
        "  x=xtr_NN;Nb=Nbranches\n",
        "\n",
        "print(xtr.shape)\n",
        "for i in range(Nb):\n",
        "  print(i)\n",
        "  # Sample data\n",
        "  x1 = x[:,2*i]\n",
        "  x2 = x[:,2*i+1]\n",
        "  # Create a scatter plot\n",
        "  plt.scatter(x1, x2)\n",
        "\n",
        "# Set plot title and labels\n",
        "plt.title('SSNN prediction')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "\n",
        "# Set equal aspect ratio for the plot\n",
        "plt.axis('square')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wnnYvzfYzEnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate $Activity$"
      ],
      "metadata": {
        "id": "Ij-gJC7G3wHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(Nbranches):\n",
        " activity=model.activity_single_branch(i,xtr,xtr_NN)\n",
        " print(\"Activity=\",activity)\n",
        "\n",
        "activities=   model.list_activities(xtr,xtr_NN)\n",
        "print(\"\\n List of activities=\",activities)\n",
        "\n",
        "index_reference=np.argmax(activities)\n",
        "print(\"\\n Index of reference=\",index_reference)"
      ],
      "metadata": {
        "id": "htbVRX2L3wMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate group metrics: $d_{closed}$ and $d_{inverse}$"
      ],
      "metadata": {
        "id": "khYUEc5W3tgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D_NN=model.obtain_list_branch_matrices_ref(index_reference)\n",
        "#print(\"List mat=\\n\",D_NN)\n",
        "\n",
        "# Print the array in a human-readable format\n",
        "for i,arr in enumerate(D_NN):\n",
        "  print(\"D=\",i)\n",
        "  np.savetxt(sys.stdout, arr, fmt='%f')\n",
        "\n",
        "print(\"\\n d_closed metrics=\",model.calculate_d_closed(index_reference))\n",
        "print(\" d_inverse metrics=\",model.calculate_d_inv(index_reference))"
      ],
      "metadata": {
        "id": "Q8aVyLbcCUh2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}